{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb095660",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import backtrader as bt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import riskfolio as rp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from simple_report import simple_backtest\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1528bf5-b8a1-4f5e-a842-c27a822750ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preprocess import IAM_data_setup, download_IAM, SelectIndex, generate_interval\n",
    "from Data_Preprocess import calculate_returns, calculate_date_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981692f-8c5a-4099-9a85-cf134d52632e",
   "metadata": {},
   "source": [
    "### Different Ticker sets from US and Hong Kong among equity/Bond, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eea6a6-43d8-42a9-98eb-7a0c7f9f3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndexSymbols(idx_n):\n",
    "    symbols =[]\n",
    "    if idx_n==\"HSI\":\n",
    "        mkt = pd.read_html('https://en.wikipedia.org/wiki/Hang_Seng_Index')\n",
    "        alist = mkt[6]['Ticker'].to_list()\n",
    "        # print(alist)\n",
    "        symbols= [sy.replace('SEHK:\\xa0', '').zfill(4)+\".HK\" for sy in alist]\n",
    "        symbols.sort()\n",
    "    elif idx_n==\"DJI\":\n",
    "        dji = pd.read_html('https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average')\n",
    "        symbols= dji[2].Symbol.tolist()       \n",
    "        symbols.sort()\n",
    "    print(symbols)\n",
    "    return symbols      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbc529-4081-4766-b836-a02fc292bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_markets(i):\n",
    "    # Tickers of assets\n",
    "    stocks_=[]\n",
    "    sector_=[]\n",
    "    class_=[]\n",
    "    # 0 selection\n",
    "    stocks_.append( ['JCI', 'TGT', 'CMCSA', 'CPB', 'MO', 'APA', 'MMC', 'JPM',\n",
    "              'ZION', 'PSA', 'BAX', 'BMY', 'LUV', 'PCAR', 'TXT', 'TMO',\n",
    "              'DE', 'MSFT', 'HPQ', 'SEE', 'VZ', 'CNP', 'NI', 'T', 'BA',\n",
    "               ])\n",
    "    sector_.append(['Consumer Discretionary','Consumer Discretionary',\n",
    "                                  'Consumer Discretionary', 'Consumer Staples',\n",
    "                                  'Consumer Staples','Energy','Financials',\n",
    "                                  'Financials','Financials','Financials',\n",
    "                                  'Health Care','Health Care','Industrials','Industrials',\n",
    "                                  'Industrials','Health Care','Industrials',\n",
    "                                  'Information Technology','Information Technology',\n",
    "                                  'Materials','Telecommunications Services','Utilities',\n",
    "                                  'Utilities','Telecommunications Services','Financials',\n",
    "                    ])\n",
    "    class_.append([\n",
    "                'Equity','Equity','Equity','Equity','Equity',\n",
    "                'Equity','Equity','Equity','Equity','Equity',\n",
    "                'Equity','Equity','Equity','Equity','Equity',\n",
    "                'Equity','Equity','Equity','Equity','Equity',\n",
    "                'Equity','Equity','Equity','Equity','Equity',\n",
    "                ])\n",
    "   # 1 selection\n",
    "    stocks_.append(['JCI', 'TGT', 'CMCSA', 'CPB', 'MO', 'APA', 'MMC', 'JPM',\n",
    "                  'ZION', 'PSA', 'BAX', 'BMY', 'LUV', 'PCAR', 'TXT', 'TMO',\n",
    "                  'DE', 'MSFT', 'HPQ', 'SEE', 'VZ', 'CNP', 'NI', 'T', 'BA',\n",
    "                    'HYG','LQD','TLT'\n",
    "                  ])\n",
    "    sector_.append(['Consumer Discretionary','Consumer Discretionary',\n",
    "                      'Consumer Discretionary', 'Consumer Staples',\n",
    "                      'Consumer Staples','Energy','Financials',\n",
    "                      'Financials','Financials','Financials',\n",
    "                      'Health Care','Health Care','Industrials','Industrials',\n",
    "                      'Industrials','Health Care','Industrials',\n",
    "                      'Information Technology','Information Technology',\n",
    "                      'Materials','Telecommunications Services','Utilities',\n",
    "                      'Utilities','Telecommunications Services','Financials',\n",
    "                         'Corporate','Corporate','Treasury',\n",
    "                    ])\n",
    "    class_.append([\n",
    "                    'Equity','Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity','Equity',\n",
    "                   'Fixed Income','Fixed Income','Fixed Income', \n",
    "                ])\n",
    "    # 2 selection\n",
    "    stocks_.append([\n",
    "                    'AMAT', 'AMD','AVGO',  \n",
    "                    'BAC','BKR','BMY','BSX',\n",
    "                    'C','CMCSA',\n",
    "                    'CSCO','CSX','CVS','CVX',\n",
    "                    'DIS','DVN',\n",
    "                    'FCX','FNF','GEN','GILD',\n",
    "                    'GM','HAL','HPQ','INTC',\n",
    "                    'IPG','JNJ','KDP',\n",
    "                    'KKR','KMI','KO',\n",
    "                    'MDLZ','MO','MRK','MRO',\n",
    "                    'MRVL','MSFT','MU','NEM',\n",
    "                ])\n",
    "    \n",
    "    sector_.append([\n",
    "                    'Technology','Technology','Technology',\n",
    "                    'Financial Services','Energy','Healthcare','Healthcare',\n",
    "                    'Financial Services','Communication Services',\n",
    "                    'Technology','Industrials','Healthcare','Energy',\n",
    "                    'Communication Services','Energy',\n",
    "                    'Basic Materials','Financial Services','Technology','Healthcare',\n",
    "                    'Consumer Cyclical','Energy','Technology','Technology',\n",
    "                    'Communication Services','Healthcare','Consumer Defensive',\n",
    "                    'Financial Services','Energy','Consumer Defensive',\n",
    "                    'Consumer Defensive','Consumer Defensive','Healthcare','Energy',\n",
    "                    'Technology','Technology','Technology','Basic Materials',\n",
    "            ])\n",
    "    class_.append([\n",
    "                    'Equity', 'Equity','Equity',  \n",
    "                    'Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity',\n",
    "                    'Equity','Equity','Equity','Equity',\n",
    "                ])\n",
    "    # 3 selection - ALL US ETF\n",
    "    stocks_.append(['HYG','LQD','TLT',\n",
    "                    'EFA','EWW','EWZ',\n",
    "                    'GLD','SLV','XME',\n",
    "                    'XLE','XOP',\n",
    "                    'DBA',\n",
    "                    'XBI',\n",
    "                    'VNQ','XHB',\n",
    "                    'IWM','QQQ', 'SPY'\n",
    "                   ])\n",
    "    sector_.append(['Corporate','Corporate','Treasury',\n",
    "                    'International','International','International',\n",
    "                    'Metal','Metal','Metal',\n",
    "                    'Energy','Energy',\n",
    "                    'Agriculture',\n",
    "                    'Healthcare',\n",
    "                    'Real Estate','Real Estate',\n",
    "                    'US Market','US Market','US Market',\n",
    "                    ])\n",
    "    class_.append( ['Fixed Income','Fixed Income','Fixed Income',\n",
    "                    'Equity', 'Equity','Equity',  \n",
    "                    'Commodity','Commodity','Commodity',\n",
    "                    'Commodity','Commodity',\n",
    "                    'Commodity',\n",
    "                    'Equity',\n",
    "                    'Equity','Equity',\n",
    "                    'Equity','Equity','Equity',\n",
    "                    ])\n",
    "    if i==\"US-ETF\":\n",
    "        return IAM_data_setup('US-ETF.txt')\n",
    "\n",
    "    if i==\"TM-CHINA\":\n",
    "        return IAM_data_setup('TM-China-2022.txt')\n",
    "\n",
    "    if i==\"TM-ASIA\":\n",
    "        return IAM_data_setup('TM-Asia-2022.txt')\n",
    "     \n",
    "    if i==\"IAM\":\n",
    "        return IAM_data_setup()\n",
    "\n",
    "    if i==\"IAMHKD\":\n",
    "        a, df = IAM_data_setup()\n",
    "        df = df[df['Currency']=='HKD']\n",
    "        return df.Assets.to_list(), df\n",
    "     \n",
    "    if i==\"IAMUSD\":\n",
    "        a, df = IAM_data_setup()\n",
    "        df = df[df['Currency']=='USD']\n",
    "        return df.Assets.to_list(), df\n",
    "\n",
    "    if i==\"IAMHKDUST\":\n",
    "        a, df = IAM_data_setup()\n",
    "        df[(df['Currency']=='HKD') | (df['Sector']=='Treasury')]\n",
    "        return df.Assets.to_list(), df\n",
    "    if (i==\"HSI\")or (i==\"DJI\"):\n",
    "        s_list = IndexSymbols(i)\n",
    "        c_l = ['Equity']*len(s_list)\n",
    "        df = pd.DataFrame({'Assets': s_list, 'Class':c_l})\n",
    "        df['Sector'] = 'General'\n",
    "        if (i=='DJI'):\n",
    "            df['Currency'] = \"USD\"\n",
    "            df['Rate'] = 1.0\n",
    "        elif (i==\"HSI\"):\n",
    "            df['Currency'] = \"HKD\"\n",
    "            df['Rate'] = 0.1282\n",
    "        print(df)\n",
    "        return s_list, df\n",
    "        \n",
    "    assets = stocks_[i]\n",
    "    asset_classes_dict = {'Assets': assets,  \n",
    "                     'Class': class_[i],\n",
    "                     'Sector': sector_[i],\n",
    "                    }\n",
    "    \n",
    "    asset_classes = pd.DataFrame(asset_classes_dict)\n",
    "    asset_classes = asset_classes.sort_values(by=['Assets'])\n",
    "    asset_classes['Currency'] = \"USD\"\n",
    "    asset_classes['Rate'] = 1.0\n",
    "    \n",
    "    assets.sort()\n",
    "\n",
    "    return assets, asset_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59912f65-3b8d-49b3-8ae5-a9deb274281d",
   "metadata": {},
   "source": [
    "### Parameters Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db127ce7-7e47-4b7d-822a-fde5530bc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalance mode\n",
    "RebalanceMode = True\n",
    "backtest_flag = \"bt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b318e4-e9d8-4fe8-8297-c45bd78c4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RebalanceMode:\n",
    "    # end is today \n",
    "    n = 1600\n",
    "    # end = dt.datetime.today().date()\n",
    "    end = dt.datetime(2024, 12, 7)\n",
    "    start = end - dt.timedelta(days=n)\n",
    "    datetag = end.strftime(\"RB_%Y-%m-%d\")\n",
    "    \n",
    "    subfd = \"Rebalance\"\n",
    "else:\n",
    "    start = '2000-01-01'\n",
    "    end = '2024-09-30'\n",
    "    # start = '2019-01-01'\n",
    "    # end = '2024-11-01'\n",
    "    datetag = \"BT\"\n",
    "    subfd = \"BT-2000-2024\"\n",
    "print(start, ',', end, \"    tag=\", datetag)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847831f-01d7-478a-a0fe-32d353f1a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFlag = True\n",
    "useConstraint = True\n",
    "useView = True\n",
    "\n",
    "# Risk Measures available:\n",
    "#\n",
    "# 'MV': Standard Deviation.\n",
    "# 'MAD': Mean Absolute Deviation.\n",
    "# 'MSV': Semi Standard Deviation.\n",
    "# 'FLPM': First Lower Partial Moment (Omega Ratio).\n",
    "# 'SLPM': Second Lower Partial Moment (Sortino Ratio).\n",
    "# 'CVaR': Conditional Value at Risk.\n",
    "# 'EVaR': Entropic Value at Risk.\n",
    "# 'WR': Worst Realization (Minimax)\n",
    "# 'MDD': Maximum Drawdown of uncompounded cumulative returns (Calmar Ratio).\n",
    "# 'ADD': Average Drawdown of uncompounded cumulative returns.\n",
    "# 'CDaR': Conditional Drawdown at Risk of uncompounded cumulative returns.\n",
    "# 'EDaR': Entropic Drawdown at Risk of uncompounded cumulative returns.\n",
    "# 'UCI': Ulcer Index of uncompounded cumulative returns.\n",
    "\n",
    "rms = ['MV', 'MAD', 'MSV', 'FLPM', 'SLPM', 'CVaR',\n",
    "       'EVaR', 'WR', 'MDD', 'ADD', 'CDaR', 'UCI', 'EDaR']\n",
    "# rms = ['MV','WR','CVaR']\n",
    "\n",
    "# Objective Functions \n",
    "objectives = ['Sharpe', 'MinRisk', 'MaxRet']\n",
    "# objectives = [ 'MaxRet']\n",
    "\n",
    "# rebalance interval: Monthly, Quarterly, Semiannually\n",
    "# reb_interval = [\"W\",\"M\",\"Q\",\"S\"]\n",
    "reb_interval = [\"W\"]\n",
    "in_str = \"\".join(reb_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448d05e-538a-4f3b-8b1d-f6077485ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "\n",
    "params = []\n",
    "params.append({\"dset\":\"IAM\", \"const\":3})\n",
    "params.append({\"dset\":\"US-ETF\", \"const\":3})\n",
    "params.append({\"dset\":\"HSI\", \"const\":3})\n",
    "params.append({\"dset\":\"DJI\", \"const\":3})\n",
    "params.append({\"dset\":\"TM-CHINA\", \"const\":3})\n",
    "params.append({\"dset\":\"TM-ASIA\", \"const\":3})\n",
    "pi=5\n",
    "assets_selection = params[pi][\"dset\"]\n",
    "constraints_selection = params[pi][\"const\"]\n",
    "\n",
    "assets, asset_classes = sample_markets(assets_selection)\n",
    "\n",
    "display(asset_classes['Sector'].unique())\n",
    "display(asset_classes['Class'].unique())\n",
    "print(assets)\n",
    "\n",
    "outputp = os.path.join(subfd, f\"Classic_{assets_selection}_C{constraints_selection}_{in_str}_{backtest_flag}_{datetag}\")\n",
    "print(outputp)\n",
    "if not os.path.exists(outputp):\n",
    "        os.makedirs(outputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a80ca-d31d-4707-84d1-8be31fdde2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"** Number of assets:{len(assets)} ** \\n\")\n",
    "print(assets)\n",
    "print(f\"\\n ** Asset Classes Shape: {asset_classes.shape} **\")\n",
    "display(asset_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d3c50-ca85-434a-9997-28de485fdd09",
   "metadata": {},
   "source": [
    "### Setup constraints and Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aab5e5-e738-49dc-ae11-02d5e168fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#Â Building Constraints\n",
    "############################################################\n",
    "def Gen_Constraints():\n",
    "    constraints = []\n",
    "    constraints.append(pd.DataFrame({'Disabled': [False, True, False,False,True],\n",
    "                   'Type': ['All Assets', 'All Classes', 'Classes','Classes','All Assets'],\n",
    "                   'Set': ['', 'Sector', 'Class','Class',''],\n",
    "                   'Position': ['', '', 'Equity','Fixed Income',''],\n",
    "                   'Sign': ['<=', '<=', '<=','<=','>='],\n",
    "                   'Weight': [0.10, 0.20, 0.6, 0.4, 0.02],\n",
    "                   'Type Relative': ['', '', '','',''],\n",
    "                   'Relative Set': ['', '', '','',''],\n",
    "                   'Relative': ['', '', '','',''],\n",
    "                   'Factor': ['', '', '','','']}))\n",
    "    \n",
    "    constraints.append(pd.DataFrame({'Disabled': [False, False,False],\n",
    "                   'Type': ['All Assets', 'Classes','Classes'],\n",
    "                   'Set': ['', 'Class','Class'],\n",
    "                   'Position': ['', 'Equity','Fixed Income'],\n",
    "                   'Sign': ['<=', '<=','<='],\n",
    "                   'Weight': [0.10, 0.6, 0.4],\n",
    "                   'Type Relative': ['', '', ''],\n",
    "                   'Relative Set': ['', '', ''],\n",
    "                   'Relative': ['', '', ''],\n",
    "                   'Factor': ['', '', '']}))\n",
    "    \n",
    "    constraints.append(pd.DataFrame({'Disabled': [False, False, False],\n",
    "                   'Type': ['All Assets', 'All Classes', 'All Classes'],\n",
    "                   'Set': ['', 'Sector', 'Sector'],\n",
    "                   'Position': ['', '', ''],\n",
    "                   'Sign': ['<=', '<=', '>='],\n",
    "                   'Weight': [0.10, 0.20, 0.03],\n",
    "                   'Type Relative': ['', '', ''],\n",
    "                   'Relative Set': ['', '', ''],\n",
    "                   'Relative': ['', '', ''],\n",
    "                   'Factor': ['', '', '']}))\n",
    "    \n",
    "    constraints.append(pd.DataFrame({'Disabled': [False],\n",
    "                   'Type': ['All Assets'],\n",
    "                   'Set': [''],\n",
    "                   'Position': [''],\n",
    "                   'Sign': ['<='],\n",
    "                   'Weight': [0.10],\n",
    "                   'Type Relative': [''],\n",
    "                   'Relative Set': [''],\n",
    "                   'Relative': [''],\n",
    "                   'Factor': ['']\n",
    "                  }))\n",
    "\n",
    "    constraints.append(pd.DataFrame({'Disabled': [False],\n",
    "                   'Type': ['All Assets'],\n",
    "                   'Set': [''],\n",
    "                   'Position': [''],\n",
    "                   'Sign': ['<='],\n",
    "                   'Weight': [0.15],\n",
    "                   'Type Relative': [''],\n",
    "                   'Relative Set': [''],\n",
    "                   'Relative': [''],\n",
    "                   'Factor': ['']\n",
    "                  }))\n",
    "\n",
    "    constraints.append(pd.DataFrame({'Disabled': [False],\n",
    "                   'Type': ['All Assets'],\n",
    "                   'Set': [''],\n",
    "                   'Position': [''],\n",
    "                   'Sign': ['<='],\n",
    "                   'Weight': [0.25],\n",
    "                   'Type Relative': [''],\n",
    "                   'Relative Set': [''],\n",
    "                   'Relative': [''],\n",
    "                   'Factor': ['']\n",
    "                  }))\n",
    "    \n",
    "    return constraints\n",
    "\n",
    "global_constraint_list = Gen_Constraints()\n",
    "max_g_const = len(global_constraint_list)\n",
    "print(f\"Total {max_g_const} constraints for selection\")\n",
    "constraints = global_constraint_list[constraints_selection]\n",
    "display(\"Current selected constraints:\")\n",
    "display(constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012dbb6a-79f5-4efd-9ac3-fa476667138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Building View for Black Litterman\n",
    "############################################################\n",
    "views = {'Disabled': [False, False, False],\n",
    "         'Type': ['Classes', 'Classes', 'Classes'],\n",
    "         'Set': ['Sector', 'Sector', 'Sector'],\n",
    "         'Position': ['Technology', 'Energy', 'Healthcare'],\n",
    "         'Sign': ['>=', '>=', '>='],\n",
    "         'Weight': [0.20, 0.1, 0.09], # Annual terms \n",
    "         'Type Relative': ['Classes', 'Classes', 'Classes'],\n",
    "         'Relative Set': ['Sector', 'Sector', 'Sector'],\n",
    "         'Relative': ['Financial Services', 'Commodity', 'Consumer Defensive']}\n",
    "\n",
    "views = pd.DataFrame(views)\n",
    "\n",
    "display(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ed324-db3b-44fc-a0fd-f1b742af7ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to create Constraint and Views by a subset of tickers\n",
    "\n",
    "def get_Constraint(subSet):\n",
    "    sub_asset_classes = asset_classes.loc[asset_classes['Assets'].isin(subSet)]\n",
    "    # print(f'Constraint-> subSet={subSet}, sub_asset_classes={sub_asset_classes}\\n')\n",
    "    return rp.assets_constraints(constraints, sub_asset_classes)\n",
    "\n",
    "\n",
    "def get_Views(subSet):\n",
    "    sub_asset_classes = asset_classes.loc[asset_classes['Assets'].isin(subSet)]\n",
    "    # print(f'subSet={subSet}, sub_asset_classes={sub_asset_classes}\\n')\n",
    "    return rp.assets_views(views, sub_asset_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5b591",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "Full data download from yfinance to **prices** dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading data\n",
    "print('# of assets: ', len(assets))\n",
    "if (type(assets_selection)==str) and (\"IAM\" in assets_selection) and (not RebalanceMode) :\n",
    "    prices = download_IAM()\n",
    "else:\n",
    "    prices = yf.download(assets, start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572086b6-38dc-4425-9c10-9b08d311f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Size: ', prices.shape)\n",
    "prices.columns[prices.isna().sum()==prices.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prices.index[0], prices.index[-1])\n",
    "display(prices.info())\n",
    "display(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf32753-79b6-492b-b63c-5faafae58da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Calculate assets returns\n",
    "############################################################\n",
    "\n",
    "returns = calculate_returns(prices)[assets]\n",
    "print(f\"** Number of assets in returns DF: {returns.shape[1]} **\")\n",
    "print(f\"** days of assets in returns DF: {returns.shape[0]} **\")\n",
    "print(f\"** begin date: {returns.index[0]}, last date: {returns.index[-1]} **\")\n",
    "print(\"\\n** Assets in Returns Set: \", returns.columns.to_list(), \" \\n\")\n",
    "display(returns)\n",
    "returns.reset_index().to_csv(os.path.join(outputp,\"Full_Returns.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  all test is from the 1004th day and finish at the last testdata day.\n",
    "#\n",
    "start_test = 1004\n",
    "end_test = prices.shape[0] - 1\n",
    "test_size = 1000\n",
    "print(f\" Testing data from {start_test} to {end_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e49d3-192a-4d2f-bc25-61c73818219f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# from the full pricess datafraes, create the intercepted date/index for each ticker\n",
    "#\n",
    "assets_dt_range = calculate_date_range(prices, returns.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f152e0d-594d-45c3-b5cf-e3e5f28bd2ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(assets_dt_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d2863",
   "metadata": {},
   "source": [
    "### Building the Backtest Function with Backtrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Defining the backtest function \n",
    "############################################################\n",
    "\n",
    "def backtest(datas, strategy, start, end, plot=False, **kwargs):\n",
    "    cerebro = bt.Cerebro()\n",
    "\n",
    "    # print(datas)\n",
    "    print(f\"backtest:  start={start} - end={end}\\n\")\n",
    "    # Here we add transaction costs and other broker costs\n",
    "    cerebro.broker.setcash(1000000.0)\n",
    "    cerebro.broker.setcommission(commission=0.005) # Commission 0.5%\n",
    "    cerebro.broker.set_slippage_perc(0.005, # Slippage 0.5%\n",
    "                                     slip_open=True,\n",
    "                                     slip_limit=True,\n",
    "                                     slip_match=True,\n",
    "                                     slip_out=False)\n",
    "    # for data in datas:\n",
    "    for data in datas:\n",
    "        # print(f\"setting {data}\")\n",
    "        cerebro.adddata(data['data'], name=data['name'])\n",
    "\n",
    "    # Here we add the indicators that we are going to store\n",
    "    cerebro.addanalyzer(bt.analyzers.TimeReturn, timeframe=bt.TimeFrame.Days)\n",
    "    cerebro.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "    cerebro.addanalyzer(bt.analyzers.Returns)\n",
    "    cerebro.addanalyzer(bt.analyzers.LogReturnsRolling)\n",
    "    cerebro.addanalyzer(bt.analyzers.DrawDown)\n",
    "    cerebro.addanalyzer(bt.analyzers.PositionsValue)\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer)\n",
    "    cerebro.addanalyzer(bt.analyzers.PeriodStats)\n",
    "    cerebro.addanalyzer(bt.analyzers.Transactions)\n",
    "    cerebro.addanalyzer(bt.analyzers.VWR)\n",
    "    cerebro.addstrategy(strategy, **kwargs)\n",
    "    cerebro.addobserver(bt.observers.Value)\n",
    "    cerebro.addobserver(bt.observers.DrawDown)\n",
    "    results = cerebro.run(stdstats=False)\n",
    "    if plot:\n",
    "        print(f\"backtest.plot: {start}-{end}\")\n",
    "        cerebro.plot(iplot=False, start=start, end=end)\n",
    "        plt.show()\n",
    "    return results[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a43d",
   "metadata": {},
   "source": [
    "### Building Data Feeds for Backtesting\n",
    "**asset_prices** = list of all asset except 'SPY' in the bt.feeds of *OHLC + Volume*    \n",
    "**benchmark**  = 'SPY' *OHLC+Volume* in bt.feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b9e00-5921-4742-bd9a-7a3c0d547b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_asset_classes = asset_classes.set_index('Assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Create objects that contain the prices of assets\n",
    "############################################################\n",
    "# Creating Assets bt.feeds\n",
    "assets_prices = []\n",
    "for i in assets:\n",
    "    # if i not in benchmark_symbols:\n",
    "    \n",
    "    # prices_ = prices.drop(columns='Adj Close').loc[:, (slice(None), i)].dropna()\n",
    "    prices_ = prices.drop(columns='Adj Close').loc[:, (slice(None), i)]\n",
    "    prices_.columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    prices_.index = pd.to_datetime(prices_.index.date)\n",
    "    prices_.index.names = ['Date']\n",
    "    nan_cnt = prices_.isna().sum().sum()\n",
    "    R = i_asset_classes.loc[i, 'Rate']\n",
    "    display(f\"{i}, nan_cnt={nan_cnt} , {prices_.index[0]}, {prices_.index[-1]}, Rate: {R}\")\n",
    "    for c in ['Close', 'High', 'Low', 'Open']:\n",
    "        prices_[c] = prices_[c]*R\n",
    "    # display(prices_)\n",
    "    assets_prices.append({'data': bt.feeds.PandasData(dataname=prices_, name=i, plot=False), 'name':i})\n",
    "        \n",
    "print(assets_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7aad0e",
   "metadata": {},
   "source": [
    "### Buy and Hold for the BenchMark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Building the Buy and Hold strategy\n",
    "############################################################\n",
    "\n",
    "class BuyAndHold(bt.Strategy):\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        dt = dt or self.datas[0].datetime.date(0)\n",
    "        print('%s %s' % (dt.isoformat(), txt))\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def next(self):\n",
    "        if self.counter >= start_test:\n",
    "            tc = self.data.close[0]\n",
    "            th = self.data.high[0]\n",
    "            td = self.data.datetime.datetime()\n",
    "            if self.getposition(self.data).size == 0:\n",
    "                print(f'BUY @ {self.counter} - close:{tc}, high:{th} - date:{td} - name:{self.data._name}')\n",
    "                self.order_target_percent(self.data, target=0.99)\n",
    "        self.counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab372fc-4196-4d38-b885-d5f3a8b6ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Run the backtest for the bench mark(s)\n",
    "############################################################\n",
    "%matplotlib inline\n",
    "# # Creating Benchmark bt.feeds  \n",
    "# from datetime import datetime\n",
    "# import pytz\n",
    "\n",
    "benchmark_results = {}\n",
    "bm_list = [\"SPY\", \"^HSI\",\"QQQ\",\"DIA\",\"2822.HK\",\"2801.HK\", \"AAXJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc92cc-6831-4ffc-a822-ebeb5a2025c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backtest_BenchMark(symbol):\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (10, 6) # (w, h)\n",
    "    plt.plot() # We need to do this to avoid errors in inline plot\n",
    "\n",
    "    print(symbol)\n",
    "    bm_prices = yf.download(symbol, start=start, end=end)\n",
    "    prices_ = bm_prices.drop(columns='Adj Close')\n",
    "    # prices_ = prices.drop(columns='Adj Close').loc[:, (slice(None), symbol)].dropna()\n",
    "    prices_.columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    # prices_.index = pd.to_datetime(prices_.index.date)\n",
    "    # prices_.index.names = ['Date']\n",
    "    display(symbol, prices_.index[0], prices_.index[-1])\n",
    "    # display(prices_)\n",
    "    print(\"==>\", start_test, end_test)\n",
    "    in_data = {}\n",
    "    in_data['data'] = bt.feeds.PandasData(dataname=prices_, name=symbol, plot=False)\n",
    "    in_data['name'] = symbol\n",
    "    result = backtest([in_data],\n",
    "                    BuyAndHold,\n",
    "                    start=start_test,\n",
    "                    end=end_test,\n",
    "                    plot=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetreiveStats(bt_result, rm, obj, r_int):\n",
    "    dd = bt_result.analyzers.drawdown.get_analysis()['max']['drawdown']\n",
    "    cagr= bt_result.analyzers.returns.get_analysis()['rnorm100']\n",
    "    sharpe =bt_result.analyzers.sharperatio.get_analysis()['sharperatio']\n",
    "\n",
    "    return {'Risk_measure':rm, 'Objective':obj, 'R_Interval': r_int, 'Max DrawDown':dd/100.0, 'CAGR': cagr/100.0, 'Sharpe Ratio':sharpe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019598d-5476-4b49-ad18-c7944c08fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Retreive Daily Return from bt\n",
    "#\n",
    "def RetreiveDailyReturn(bt_result, s_name):\n",
    "    tret_analyzer = bt_result.analyzers.getbyname('timereturn')\n",
    "    ret_ = tret_analyzer.get_analysis()\n",
    "    return pd.DataFrame(ret_.items(), columns=['Date', s_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e05f05-9140-4030-bcc8-9c1a0346a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "BM_metric_list = []\n",
    "BM_return = {}\n",
    "\n",
    "if backtest_flag == \"bt2\":\n",
    "    bm_prices = yf.download(bm_list, start=start, end=end)\n",
    "    pm_returns = calculate_returns(bm_prices)\n",
    "    display(\"==>\", bm_list, bm_prices.index[0], bm_prices.index[-1])\n",
    "    # display(prices_)\n",
    "    results = {}\n",
    "    for sy in bm_list:\n",
    "        result, BM_ret = simple_backtest(None, pm_returns[sy].to_frame(), sy, \"N/A\", \"N/A\")\n",
    "        BM_metric_list.append(result)\n",
    "        BM_ret['Date'] = BM_ret['Date'].dt.date\n",
    "        BM_ret.round(4).to_csv(os.path.join(outputp, f\"{sy}_ret.csv\"), index=False)\n",
    "else:\n",
    "    for sym in bm_list:\n",
    "        result0 = Backtest_BenchMark(sym)\n",
    "        BM_metric_list.append(RetreiveStats(result0, sym, 'N/A', 'N/A'))\n",
    "        BM_ret = RetreiveDailyReturn(result0, sym)\n",
    "        BM_ret['Date'] = BM_ret['Date'].dt.date\n",
    "        BM_ret.round(4).to_csv(os.path.join(outputp, f\"{sym}_ret.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed097d-a2eb-4756-9abe-e98880681268",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(start_test, end_test, BM_metric_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18e42a",
   "metadata": {},
   "source": [
    "### Rebalancing Monthly, Quarterly, Semiannually using Riskfolio-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e1bfd-f478-4daf-9c77-8fd88d6a3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_index = {}\n",
    "rebalance_index[\"W\"] = SelectIndex(returns, \"W\", start_test)\n",
    "rebalance_index[\"M\"] = SelectIndex(returns, \"M\", start_test)\n",
    "rebalance_index[\"Q\"] = SelectIndex(returns, \"Q\", start_test)\n",
    "rebalance_index[\"S\"] = SelectIndex(returns, \"S\", start_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f634d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_index={}\n",
    "r_index[\"W\"] = generate_interval(returns, rebalance_index[\"W\"], os.path.join(outputp, \"rebalance_index_W.csv\"))\n",
    "r_index[\"M\"] = generate_interval(returns, rebalance_index[\"M\"], os.path.join(outputp, \"rebalance_index_M.csv\"))\n",
    "r_index[\"Q\"] = generate_interval(returns, rebalance_index[\"Q\"], os.path.join(outputp, \"rebalance_index_Q.csv\"))\n",
    "r_index[\"S\"] = generate_interval(returns, rebalance_index[\"S\"], os.path.join(outputp, \"rebalance_index_S.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d31875-16f1-4639-9c0b-cfe06cab669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_index[\"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e76ab-7c2c-4b99-8dcd-f909c3899323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_return_set(ret, s_i, e_i):\n",
    "    # i_ret = ret.reset_index()\n",
    "    i_ret = ret.iloc[s_i: e_i,:].dropna(axis=1)\n",
    "    return i_ret\n",
    "\n",
    "nY = get_return_set(returns, 40, 1040)\n",
    "display(nY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbbbe49",
   "metadata": {},
   "source": [
    "* The optimization is based on the returns of previous 1000 days from last date of each quarter, which is about 4 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8991d-3ba8-42a4-b741-3c680c6865f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def opt_worker(d_cnt, data):\n",
    "    created = multiprocessing.Process()\n",
    "    current = multiprocessing.current_process()\n",
    "    print(f' running: {current.name}, {current._identity}\\n created: {created.name}, {created._identity}\\n')\n",
    "\n",
    "    results=[]\n",
    "    for i in range(len(data)):\n",
    "        obj, r, rm = data[i]['keys']\n",
    "        print(f'started for {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "\n",
    "        result={}\n",
    "        result['keys'] = data[i]['keys']\n",
    "        \n",
    "        start_time = time.time()\n",
    "        weights = pd.DataFrame(columns=returns.columns.to_list())\n",
    "        # for j in rebalance_index[r]:\n",
    "        for j, dt in r_index[r].iterrows():\n",
    "\n",
    "            try:\n",
    "                # Y = returns.iloc[j-test_size:j,:] # taking last 4 years (250 trading days per year)\n",
    "                Y = get_return_set(returns, j-test_size, j)\n",
    "                orig_size = len(Y.columns.to_list())\n",
    "                # filter holidays i.e. all ticker has no data at 'all'\n",
    "                # Y = Y.dropna(axis=0, how='all')\n",
    "                # then filter out ticker that cannot supply full data set\n",
    "                # Y = Y.dropna(axis=1, how='any')\n",
    "                aSet = Y.columns.to_list()\n",
    "                col_num = len(Y.columns.to_list())\n",
    "               \n",
    "                # Building the portfolio object\n",
    "                print(f'Create Port: {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}, Y cols={col_num}/{orig_size}\\n')\n",
    "                port = rp.Portfolio(returns=Y)\n",
    "                \n",
    "                port.alpha = 0.05\n",
    "                model='BL' # Could be Classic (historical), BL (Black Litterman) or FM (Factor Model)\n",
    "                hist = False # Use historical scenarios for risk measures that depend on scenarios\n",
    "                rf = 0 # Risk free rate\n",
    "                l = 0 # Risk aversion factor, only useful when obj is 'Utility'\n",
    "                \n",
    "                # Add portfolio constraints\n",
    "                if useView:\n",
    "                    P,Q = get_Views(aSet)\n",
    "                if useConstraint:\n",
    "                    A, B = get_Constraint(aSet)\n",
    "                    port.ainequality = A\n",
    "                    port.binequality = B\n",
    "                \n",
    "                # Calculating optimum portfolio\n",
    "                \n",
    "                # Select method and estimate input parameters:\n",
    "                \n",
    "                method_mu='hist' # Method to estimate expected returns based on historical data.\n",
    "                method_cov='hist' # Method to estimate covariance matrix based on historical data.\n",
    "                \n",
    "                # print(f'assets_stats: {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "                port.assets_stats(method_mu=method_mu, method_cov=method_cov)\n",
    "                \n",
    "                # Estimate optimal portfolio:\n",
    "                # print(f'optimization(Classic): {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "                out_w = port.optimization(model='Classic', rm=rm, obj=obj, rf=rf, l=l, hist=True)\n",
    "                print(f\"opt result for {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}--out_w: {len(out_w)}:{out_w}\\n\")\n",
    "                w = out_w\n",
    "                \n",
    "                # # Estimate Black Litterman inputs:\n",
    "                # print(f'blacklitterman_stats: {obj}, {r}, {rm} == {i}/{len(data)} {current.name}\\n')\n",
    "                # port.blacklitterman_stats(P, Q/252, rf=rf, w=w, delta=None, eq=True)\n",
    "                \n",
    "                # if rm == 'MV':\n",
    "                #     hist = False\n",
    "                # else:\n",
    "                #     hist = True\n",
    "                # print(f'optimization({model}): {obj}, {r}, {rm} == {i}/{len(data)} {current.name}\\n')\n",
    "                # w = port.optimization(model=model, rm=rm, obj=obj, rf=rf, l=l, hist=hist)\n",
    "            except Exception as e:\n",
    "                print(f'Exception:{e} -- {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "                w = None\n",
    "            \n",
    "            if w is None:\n",
    "                w = weights.tail(1).T\n",
    "            weights = pd.concat([weights, w.T], axis = 0)\n",
    "     \n",
    "        totalt = time.time()-start_time\n",
    "        print(f\"Finished for {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}--{totalt} sec--\\n\")\n",
    "        # if len(weights) == len(rebalance_index[r]):\n",
    "        #     weights.index = rebalance_index[r]\n",
    "        if len(weights) == len(r_index[r]):\n",
    "            weights.index = r_index[r].index  \n",
    "            weights.insert(0, 'Date', r_index[r]['Date'])\n",
    "             \n",
    "        result['weights'] = weights\n",
    "        results.append(result) \n",
    "    print(f'Existing: {current.name}, {current._identity}\\n')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f3968-247f-4070-9c20-94f648ed867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_workerv2(d_cnt, data):\n",
    "    created = multiprocessing.Process()\n",
    "    current = multiprocessing.current_process()\n",
    "    print(f' running: {current.name}, {current._identity}\\n created: {created.name}, {created._identity}\\n')\n",
    "\n",
    "    results=[]\n",
    "    for i in range(len(data)):\n",
    "        obj, r, rm = data[i]['keys']\n",
    "        print(f'started for {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "\n",
    "        result={}\n",
    "        result['keys'] = data[i]['keys']\n",
    "        \n",
    "        start_time = time.time()\n",
    "        weights = pd.DataFrame(columns=[\"index\",\"Date\"] + returns.columns.to_list())\n",
    "        datasets = []\n",
    "        result['datasets'] = datasets\n",
    "        count=0\n",
    "        for j, dt in r_index[r].iterrows():\n",
    "            dataset = {}\n",
    "            dataset['data_block'] = (j-test_size, j, dt['Date'])\n",
    "\n",
    "            try:\n",
    "                orig_size = len(returns.columns.to_list())            \n",
    "                Y = get_return_set(returns, j-test_size, j)\n",
    "                aSet = Y.columns.to_list()\n",
    "                col_num = len(Y.columns.to_list())\n",
    "               \n",
    "                # Building the portfolio object\n",
    "                # print(f'Create Port[{j}]: {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}, Y cols={col_num}/{orig_size}\\n')\n",
    "                port = rp.Portfolio(returns=Y)\n",
    "                dataset['data_size'] = Y.shape\n",
    "                dataset['data_asset'] = Y.columns.to_list()\n",
    "                dataset['assets_ratio'] = (orig_size, col_num)\n",
    "                \n",
    "                port.alpha = 0.05\n",
    "                model='BL' # Could be Classic (historical), BL (Black Litterman) or FM (Factor Model)\n",
    "                hist = False # Use historical scenarios for risk measures that depend on scenarios\n",
    "                rf = 0 # Risk free rate\n",
    "                l = 0 # Risk aversion factor, only useful when obj is 'Utility'\n",
    "                \n",
    "                # Add portfolio constraints\n",
    "                if useView:\n",
    "                    P,Q = get_Views(aSet)\n",
    "                if useConstraint:\n",
    "                    A, B = get_Constraint(aSet)\n",
    "                    # print(f'==> Port Constraint[{j}]: {obj}, {r}, {rm} == A:{A.shape},B:{B.shape}, Y cols={col_num}/{orig_size}\\n')\n",
    "                    port.ainequality = A\n",
    "                    port.binequality = B\n",
    "                \n",
    "                # Calculating optimum portfolio\n",
    "                \n",
    "                # Select method and estimate input parameters:\n",
    "                \n",
    "                method_mu='hist' # Method to estimate expected returns based on historical data.\n",
    "                method_cov='hist' # Method to estimate covariance matrix based on historical data.\n",
    "                \n",
    "                # print(f'assets_stats: {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "                port.assets_stats(method_mu=method_mu, method_cov=method_cov)\n",
    "                \n",
    "                # Estimate optimal portfolio:\n",
    "                # print(f'optimization(Classic): {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "                w = port.optimization(model='Classic', rm=rm, obj=obj, rf=rf, l=l, hist=True)\n",
    "                # print(f\"opt result for {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}--out_w=:\\n{w}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f'Exception[{j}]:{e} -- {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "                w = None\n",
    "            \n",
    "            if (w is None) and (len(weights)>0):\n",
    "                w = weights.tail(1)\n",
    "                if \"index\" in w.columns.to_list():\n",
    "                    w.drop(columns=[\"index\"], inplace=True)\n",
    "                if \"Date\" in w.columns.to_list():\n",
    "                    w.drop(columns=[\"Date\"], inplace=True)\n",
    "                w = w.T            \n",
    "            count +=1\n",
    "            if (w is not None) and (len(w)>0):\n",
    "                dataset['w_asset'] = w.columns.to_list()\n",
    "                wT = w.T\n",
    "                wT.insert(0, \"Date\", [dt.Date])\n",
    "                wT.insert(0, \"index\", [j])\n",
    "                # display(weights)\n",
    "                # display(wT)\n",
    "                weights = pd.concat([weights, wT], axis = 0)\n",
    "                # display(weights)\n",
    "                # print(f\"*** [{j}] {obj}, {r}, {rm} == weights.size:{weights.shape[0]}/{count}/{len(r_index[r])}    {current.name}\\n\")\n",
    "            datasets.append(dataset)\n",
    "        totalt = time.time()-start_time\n",
    "        # print(f\"Finished for {obj}, {r}, {rm} == {i}/{d_cnt} {current.name}--{totalt} sec--\\n\")\n",
    "        # display(weights)\n",
    "        weights = weights.set_index(\"index\")\n",
    "        if len(weights) != len(r_index[r]):    \n",
    "            lw = len(weights)\n",
    "            lr = len(r_index[r])\n",
    "            print(f\"*** [{j}] {obj}, {r}, {rm} == weights.len/r_index.len   {lw}/{lr}    {current.name}\\n\")\n",
    "            \n",
    "        result['weights'] = weights\n",
    "        results.append(result) \n",
    "    print(f'Existing: {current.name}, {current._identity}\\n')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99cd4ac-b4cb-470e-a371-3828d9a5e3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Generate a list of parameters for the multi-processing optimization function\n",
    "##\n",
    "\n",
    "models = {}\n",
    "data_chunks = []\n",
    "for obj in objectives:\n",
    "    models[obj] = {}\n",
    "    for r in reb_interval:\n",
    "        models[obj][r] = {}\n",
    "        for rm in rms:\n",
    "            print(obj, \",\", r, \",\", rm)\n",
    "            weights = pd.DataFrame([])\n",
    "            data_chunks.append({\"keys\":(obj, r, rm)})\n",
    "\n",
    "# display(data_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967e38b-fc37-401c-80f7-8130a3f69174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data_chunks)\n",
    "display(data_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b683928-d8e9-4f29-b0f4-d9c99e432301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from data_processing_v2 import run_pool_v2, set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "# Run with a specified number of CPUs\n",
    "\n",
    "opt_resultsv2 = run_pool_v2(data_chunks, opt_workerv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c3b84-9fe4-4622-b42b-256144212b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_resultsv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3456464-8aaa-4fc6-8bcc-714f9be07706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(f\"Optimized result length: {len(opt_resultsv2)}\")\n",
    "models = []\n",
    "for batch in opt_resultsv2:\n",
    "    for result in batch:\n",
    "        obj,r,rm = result['keys']\n",
    "        # w = result['weights'].fillna(0)\n",
    "        w = result['weights']\n",
    "        print(obj,r,rm)\n",
    "        # print('w.shape: ', w.shape)\n",
    "        # print(returns.isna().sum())\n",
    "        # print(w.columns[w.isna().sum()==w.shape[0]])      \n",
    "        w.round(4).to_csv(os.path.join(outputp,f\"weights_{obj}_{r}_{rm}.csv\"))\n",
    "        model = {'keys': result['keys'], 'weights': w}\n",
    "        models.append(model)\n",
    "        \n",
    "display(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115890fe-2100-4176-a87f-623f6ab78550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# create parameters list for process pool\n",
    "#\n",
    "# target = ('MaxRet','S','WR')\n",
    "target=None\n",
    "parameters=[]\n",
    "for arg in models:\n",
    "    if (target is None) or (arg['keys'] == target):\n",
    "        param={}\n",
    "        param['keys'] = arg['keys']\n",
    "        display(param['keys'])\n",
    "        param['weights'] = arg['weights'].round(4)\n",
    "        # display(param['weights'])\n",
    "        parameters.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1ce9d-5159-42a0-b977-d4dc0620f182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Building the Asset Allocation Class\n",
    "############################################################\n",
    "\n",
    "class AssetAllocation(bt.Strategy):\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        dt = dt or self.data.datetime[0]\n",
    "        dt = bt.num2date(dt)\n",
    "        print('\\n{}: {}'.format(dt.isoformat(), txt))\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self._n_assets = len(self.datas)\n",
    "        self._weights = None\n",
    "        self._assets = None\n",
    "        self._data_key = \"N/A\"\n",
    "        self.counter = 0\n",
    "        print(f\"length of datas: {self._n_assets}\")\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            print(f\"init(key: {key})\")\n",
    "            if key==\"data_keys\":\n",
    "                self._data_key = value\n",
    "                \n",
    "            if key==\"assets\":\n",
    "                self._assets = value\n",
    "                l_assets = len(self._assets)\n",
    "                print(f\"init({self._data_key}) _assets({l_assets}): {self._assets}\")\n",
    "                for i in range(self._n_assets):\n",
    "                    _n = self.datas[i]._name\n",
    "                    if _n in self._assets:\n",
    "                        print(f\"init>> assets[{i}]-{_n} in weights\")\n",
    "                        setattr(self, _n, self.datas[i])\n",
    "\n",
    "            if key==\"weights\":\n",
    "                self._weights = value\n",
    "                w_names = self._weights.columns.to_list()\n",
    "                l_assets = len(self._assets)\n",
    "                l_weights = len(self._weights)\n",
    "                print(f\"init(weights, key={self._data_key}).names({l_weights}):  {w_names}\")\n",
    "                print(f\"l_assets:{l_assets} == l_weights:{l_weights} : \", l_assets==l_weights)\n",
    "\n",
    "            if key=='dt_index':\n",
    "                self._dt_index = value\n",
    "                print(f\"set dt_index: length={len(self._dt_index )}\")\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [bt.Order.Submitted, bt.Order.Accepted]:\n",
    "            return  # Await further notifications\n",
    "\n",
    "        if order.status == order.Completed:\n",
    "            if order.isbuy():\n",
    "                self.log('BUY COMPLETE, {:.2f}'.format(order.executed.price))\n",
    "            else:\n",
    "                selltxt = 'SELL COMPLETE, {:.2f}'.format(order.executed.price)\n",
    "                self.log(selltxt, order.executed.dt)\n",
    "        elif order.status in [order.Expired, order.Canceled, order.Margin]:\n",
    "            self.log('Order Status: {} '.format(order.Status[order.status]))\n",
    "            pass  # Simply log\n",
    "\n",
    "        # Allow new orders\n",
    "        self.orderid = None\n",
    "         \n",
    "    def next(self):\n",
    "        if self.counter in self._weights.index.tolist():\n",
    "            wght = self._weights.loc[self.counter,:].dropna()\n",
    "            dt = self._dt_index.loc[self.counter].Date\n",
    "            ww = wght\n",
    "            if ww is not None:\n",
    "                ww = ww.T\n",
    "            print(f\"next({self.counter}).Date({dt})--> wght  is:\\n {ww}\")\n",
    "            for i,w in wght.items():\n",
    "                # print(f\"==> Target.order.perc:--> {self.counter},{i},{w}\")\n",
    "                self.order_target_percent(getattr(self, i), target=w)\n",
    "        self.counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b0813-e622-4f55-824f-a07f1e9580da",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_names=[]\n",
    "for i in range(len(assets_prices)):\n",
    "    assets_prices_names.append(assets_prices[i]['name'])\n",
    "print(\"length:\", len(assets_prices_names))\n",
    "print(assets_prices_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12fd96-04a0-4fb0-a2a8-81d666c9fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_worker(d_cnt, data):\n",
    "    created = multiprocessing.Process()\n",
    "    current = multiprocessing.current_process()\n",
    "    print(f' running: {current.name}, {current._identity}\\n created: {created.name}, {created._identity}\\n')    \n",
    "    # aKey = data['keys']\n",
    "    # print(f'bt_worker: data.length={len(data)}')\n",
    "    results = []\n",
    "    for i in range(len(data)):\n",
    "        obj, r, rm = data[i]['keys']\n",
    "        _weights = data[i]['weights'].drop(columns=['Date'])\n",
    "        print(\"weights of \", data[i]['keys'])\n",
    "        display(_weights)\n",
    "        w_n = _weights.columns.to_list()\n",
    "        _assets = assets_prices_names\n",
    "        print(f\"bt_worker: {obj},{r},{rm} == weight.length:{len(_weights)},,{w_n}  {current.name}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print(f'bt_worker: {obj},{r},{rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "        result={}\n",
    "        result['keys'] = (obj,r,rm)\n",
    "\n",
    "        if len(_weights) > 0:\n",
    "            result0 = backtest(assets_prices,\n",
    "                            AssetAllocation,\n",
    "                            start=start_test,\n",
    "                            end=end_test,\n",
    "                            plot=plotFlag,\n",
    "                            assets=_assets,\n",
    "                            weights=_weights,\n",
    "                            dt_index = r_index[r],\n",
    "                            data_keys=data[i]['keys']\n",
    "                            )     \n",
    "        \n",
    "            result['metric'] = RetreiveStats(result0, rm, obj, r)\n",
    "            result['Dret'] = RetreiveDailyReturn(result0, 'Return')\n",
    "            result['ptr'] = result0\n",
    "        else:\n",
    "            result['metric'] = None\n",
    "            result['Dret'] = None\n",
    "            \n",
    "        result['w'] = _weights\n",
    "        totalt = time.time()-start_time\n",
    "        result['timestamp'] = f\"--{totalt}--\"\n",
    "\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0a4b8-ba2c-40e4-ae33-aa57c24dfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_report import simple_backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b878b8f-abfa-4198-9e69-8686777bf157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"param size: \", len(parameters))\n",
    "obj, r, rm = parameters[1]['keys']\n",
    "w = parameters[0]['weights']\n",
    "print(obj, r, rm)\n",
    "# display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2504e-a78f-45d8-b61c-b591c76fc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_bt_worker(d_cnt, data):\n",
    "    created = multiprocessing.Process()\n",
    "    current = multiprocessing.current_process()\n",
    "    print(f' running: {current.name}, {current._identity}\\n created: {created.name}, {created._identity}\\n')    \n",
    "    # aKey = data['keys']\n",
    "    # print(f'bt_worker: data.length={len(data)}')\n",
    "    results = []\n",
    "    for i in range(len(data)):\n",
    "        obj, r, rm = data[i]['keys']\n",
    "        _weights = data[i]['weights']\n",
    "        print(\"weights of \", data[i]['keys'])\n",
    "        # display(_weights)\n",
    "        w_n = _weights.drop(columns=['Date']).columns.to_list()\n",
    "        _assets = assets_prices_names\n",
    "        print(f\"simply_bt_worker: {obj},{r},{rm} == weight.length:{len(_weights)},,{w_n}  {current.name}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print(f'simply_bt_worker: {obj},{r},{rm} == {i}/{d_cnt} {current.name}\\n')\n",
    "        result={}\n",
    "        result['keys'] = (obj,r,rm)\n",
    "\n",
    "        if len(_weights) > 0:\n",
    "            result0, ret_df = simple_backtest(_weights, returns, rm, obj, r)\n",
    "            result['metric'] = result0\n",
    "            result['Dret'] = ret_df\n",
    "        else:\n",
    "            result['metric'] = None\n",
    "            result['Dret'] = None\n",
    "            \n",
    "        result['w'] = _weights.drop(columns=['Date'])\n",
    "        totalt = time.time()-start_time\n",
    "        result['timestamp'] = f\"--{totalt}--\"\n",
    "\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3c30a-96c4-42d9-9bab-4d972e5c4795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run with a specified number of CPUs\n",
    "if backtest_flag == \"bt2\":\n",
    "    bt_results = run_pool_v2(parameters, simple_bt_worker)\n",
    "else:\n",
    "    bt_results = run_pool_v2(parameters, bt_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec70d1a-d2b1-4623-a787-005812d6b680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "check_flag=True\n",
    "\n",
    "print(f'bt_results.length = {len(bt_results)}')\n",
    "metric_list=[]\n",
    "for batches in bt_results:\n",
    "    print(f'batches.length = {len(batches)}')\n",
    "    for result in batches:\n",
    "        print(f'bt_results.length = {len(bt_results)}')\n",
    "        aKey = result['keys']\n",
    "        print(aKey)\n",
    "        obj, r, rm = aKey\n",
    "        print(f'obj={obj},r={r},rm={rm}')\n",
    "        if len(result['Dret']):\n",
    "            # print(result['Dret'])\n",
    "            r_fn = f\"DailyRet_{obj}_{r}_{rm}.csv\"\n",
    "            ret_df = result['Dret']\n",
    "            ret_df['Date'] = pd.to_datetime(ret_df['Date'])\n",
    "            ret_df['Date'] = ret_df['Date'].dt.date\n",
    "            ret_df.round(4).to_csv(os.path.join(outputp,r_fn), index=False)\n",
    "            print(f\"Daily return {r_fn} saved\")\n",
    "        if len(result['w']) > 0:\n",
    "            w=result['w'].iloc[-1,:].dropna()\n",
    "            print(w)\n",
    "            if check_flag:\n",
    "                # We need matplotlib >= 3.3.0 to use this function\n",
    "                ax = rp.plot_pie(w=w, title=f'{obj}-{rm}-{r}', others=0.05, nrow=25, cmap = \"tab20\",\n",
    "                                height=6, width=10, ax=None)\n",
    "                # w.plot.pie(subplots=True, figsize=(8, 8))\n",
    "                plt.show()\n",
    "            ############################################################\n",
    "            # Composition per Industry\n",
    "            ############################################################\n",
    "            w_classes = pd.concat([asset_classes.set_index('Assets'), w], axis=1)\n",
    "            # display(w_classes)\n",
    "            w_classes = w_classes.groupby(['Sector']).sum()\n",
    "            # w_classes.columns = ['weights']  \n",
    "            # display(w_classes)\n",
    "        if result['metric'] is not None:\n",
    "            # display(result['metric'])\n",
    "            metric_list.append(result['metric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d69ed-2b6f-4b78-ab8b-6927a0f21051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BM_metric_list_df = pd.DataFrame(BM_metric_list)\n",
    "metric_df = pd.DataFrame(metric_list)\n",
    "metric_df = metric_df.sort_values(by=['CAGR','Sharpe Ratio'], ascending=False)\n",
    "full_metric = pd.concat([BM_metric_list_df, metric_df])\n",
    "display(full_metric.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e136cb7-68ae-4185-b9f0-fc3291271218",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric.to_csv(os.path.join(outputp,\"Port_Metric.csv\"), index=False)\n",
    "constraints.to_csv(os.path.join(outputp,\"Constraints.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141175f-0ad5-4735-a90b-158e173de14f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(metric_df[metric_df['R_Interval']=='Q'].sort_values(by=['Sharpe Ratio','CAGR'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5066975-ee17-42c8-8d7a-b49fb40cb138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(metric_df[metric_df['R_Interval']=='S'].sort_values(by=['Sharpe Ratio','CAGR'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285bd74f-6f01-4e29-9a61-1373cc990e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265ecc1-8868-4d60-9d95-b9e2d0c7a9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b57b8a-a748-4a3b-bc9b-ee326ee7933c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
